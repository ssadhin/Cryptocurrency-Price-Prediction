{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FLUX UPSCALER FOR IMAGES & VIDEOS**\n",
        "- **This notebook was implemented based on a ComfyUI Flux Upscale Workflow using the UltimateSDUpscale node.**\n",
        "- You can use the free T4 GPU to run this notebook, but it is much slower than others.\n",
        "-You can tick the `download_face_upscalers` checkbox in the 'Setup Environment' section before running it if you just want to upscale a face. You can then select 4xFaceUpSharpDAT.pth or 4xFaceUpSharpLDAT.pth as your upscale model.\n",
        "-You can tick the `download_loRA` checkbox in the 'Setup Environment' section before running it if you want to use a loRA from either huggingface or civitai. Remember to input your civitai token if your download link is from civitai. Then tick the `use_loRA` checkbox in the loRA settings before running the upscaling.\n",
        "- Adding prompts is optional, but it might produce better results.\n",
        "- The number of steps to use depends on the denoise value and your image or video. The more blurry the images or videos, the higher the steps and denoise values you should use. I usually make the steps 20 times the denoise value. But note that the higher the denoise value, the more different from the original your images and videos will appear. You can experiment with other settings to find out what works best for you.\n",
        "- In the video settings, you can choose to upscale every 2nd or 3rd frame from your video to speed up the process, then use the frame interpolation notebook, which is far faster than upscaling, to recover your frames and fps."
      ],
      "metadata": {
        "id": "a88vCU_V7WUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "opZ7N4bk45bp"
      },
      "outputs": [],
      "source": [
        "# @title Setup Environment\n",
        "# !pip install --quiet torch torchvision --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install --upgrade --quiet torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch==2.6.0 torchvision==0.21.0\n",
        "%cd /content\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "clear_output()\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_UltimateSDUpscale\n",
        "clear_output()\n",
        "# !git clone https://github.com/Isi-dev/ComfyUI_VideoHelperSuite\n",
        "# clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "# %cd /content/ComfyUI/custom_nodes/ComfyUI_VideoHelperSuite\n",
        "# !pip install -r requirements.txt\n",
        "clear_output()\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_pip_packages():\n",
        "    packages = [\n",
        "        'torchsde',\n",
        "        'av',\n",
        "        'diffusers',\n",
        "        # 'transformers',\n",
        "        'xformers==0.0.29.post2',\n",
        "        'accelerate',\n",
        "        # 'omegaconf',\n",
        "        # 'tqdm',\n",
        "        # 'librosa',\n",
        "        'einops',\n",
        "        'spandrel'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            # Run pip install silently (using -q)\n",
        "            subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "                check=True,\n",
        "                capture_output=True\n",
        "            )\n",
        "            print(f\"✓ {package} installed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ Error installing {package}: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "def install_apt_packages():\n",
        "    packages = ['aria2']\n",
        "\n",
        "    try:\n",
        "        # Run apt install silently (using -qq)\n",
        "        subprocess.run(\n",
        "            ['apt-get', '-y', 'install', '-qq'] + packages,\n",
        "            check=True,\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(\"✓ apt packages installed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ Error installing apt packages: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "\n",
        "print(\"Installing pip packages...\")\n",
        "install_pip_packages()\n",
        "clear_output()  # Clear the pip installation output\n",
        "\n",
        "print(\"Installing apt packages...\")\n",
        "install_apt_packages()\n",
        "clear_output()  # Clear the apt installation output\n",
        "\n",
        "print(\"Installation completed with status:\")\n",
        "print(\"- All pip packages installed successfully\" if '✗' not in install_pip_packages.__code__.co_consts else \"- Some pip packages had issues\")\n",
        "print(\"- apt packages installed successfully\" if '✗' not in install_apt_packages.__code__.co_consts else \"- apt packages had issues\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import random\n",
        "import imageio\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from nodes import (\n",
        "    DualCLIPLoader,\n",
        "    UNETLoader,\n",
        "    VAELoader,\n",
        "    LoraLoaderModelOnly,\n",
        "    LoadImage,\n",
        "    SaveImage\n",
        ")\n",
        "\n",
        "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
        "\n",
        "from comfy_extras.nodes_upscale_model import UpscaleModelLoader\n",
        "from comfy_extras.nodes_flux import CLIPTextEncodeFlux\n",
        "\n",
        "from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import (\n",
        "    UltimateSDUpscale,\n",
        "    UltimateSDUpscaleNoUpscale\n",
        ")\n",
        "\n",
        "# from custom_nodes.ComfyUI_VideoHelperSuite.nodes import\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "download_face_upscalers = False # @param {type:\"boolean\"}\n",
        "\n",
        "download_loRA = False # @param {type:\"boolean\"}\n",
        "\n",
        "lora = None\n",
        "\n",
        "def download_with_aria2c(link, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "\n",
        "    filename = link.split(\"/\")[-1]\n",
        "    command = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d {folder} -o {filename}\"\n",
        "\n",
        "    print(\"Executing download command:\")\n",
        "    print(command)\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    get_ipython().system(command)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "\n",
        "def download_civitai_model(civitai_link, civitai_token, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "    import time\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        model_id = civitai_link.split(\"/models/\")[1].split(\"?\")[0]\n",
        "    except IndexError:\n",
        "        raise ValueError(\"Invalid Civitai URL format. Please use a link like: https://civitai.com/api/download/models/1523247?...\")\n",
        "\n",
        "    civitai_url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
        "    if civitai_token:\n",
        "        civitai_url += f\"&token={civitai_token}\"\n",
        "\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"model_{timestamp}.safetensors\"\n",
        "\n",
        "    full_path = os.path.join(folder, filename)\n",
        "\n",
        "    download_command = f\"wget --max-redirect=10 --show-progress \\\"{civitai_url}\\\" -O \\\"{full_path}\\\"\"\n",
        "    print(\"Downloading from Civitai...\")\n",
        "\n",
        "    os.system(download_command)\n",
        "\n",
        "    local_path = os.path.join(folder, filename)\n",
        "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
        "        print(f\"LoRA downloaded successfully: {local_path}\")\n",
        "    else:\n",
        "        print(f\"❌ LoRA download failed or file is empty: {local_path}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def download_lora(link, folder=\"/content/ComfyUI/models/loras\", civitai_token=None):\n",
        "    \"\"\"\n",
        "    Download a model file, automatically detecting if it's a Civitai link or huggingface download.\n",
        "\n",
        "    Args:\n",
        "        link: The download URL (either huggingface or Civitai)\n",
        "        folder: Destination folder for the download\n",
        "        civitai_token: Optional token for Civitai downloads (required if link is from Civitai)\n",
        "\n",
        "    Returns:\n",
        "        The filename of the downloaded model\n",
        "    \"\"\"\n",
        "    if \"civitai.com\" in link.lower():\n",
        "        if not civitai_token:\n",
        "            raise ValueError(\"Civitai token is required for Civitai downloads\")\n",
        "        return download_civitai_model(link, civitai_token, folder)\n",
        "    else:\n",
        "        return download_with_aria2c(link, folder)\n",
        "\n",
        "flux_lora_download_url = \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/flux_realism_lora.safetensors\"# @param {\"type\":\"string\"}\n",
        "token_if_civitai_url = \"Put your civitai token here\"# @param {\"type\":\"string\"}\n",
        "\n",
        "if download_loRA:\n",
        "    lora = download_lora(flux_lora_download_url, civitai_token=token_if_civitai_url)\n",
        "# Validate loRA file extension\n",
        "valid_extensions = {'.safetensors', '.ckpt', '.pt', '.pth', '.sft'}\n",
        "if lora:\n",
        "    if not any(lora.lower().endswith(ext) for ext in valid_extensions):\n",
        "        print(f\"❌ Invalid LoRA format: {lora}\")\n",
        "        lora = None\n",
        "    else:\n",
        "        clear_output()\n",
        "        print(\"loRA downloaded succesfully!\")\n",
        "\n",
        "def model_download(url: str, dest_dir: str, filename: str = None, silent: bool = True) -> bool:\n",
        "    \"\"\"\n",
        "    Colab-optimized download with aria2c\n",
        "\n",
        "    Args:\n",
        "        url: Download URL\n",
        "        dest_dir: Target directory (will be created if needed)\n",
        "        filename: Optional output filename (defaults to URL filename)\n",
        "        silent: If True, suppresses all output (except errors)\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successful, False if failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create destination directory\n",
        "        Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Set filename if not specified\n",
        "        if filename is None:\n",
        "            filename = url.split('/')[-1].split('?')[0]  # Remove URL parameters\n",
        "\n",
        "        # Build command\n",
        "        cmd = [\n",
        "            'aria2c',\n",
        "            '--console-log-level=error',\n",
        "            '-c', '-x', '16', '-s', '16', '-k', '1M',\n",
        "            '-d', dest_dir,\n",
        "            '-o', filename,\n",
        "            url\n",
        "        ]\n",
        "\n",
        "        # Add silent flags if requested\n",
        "        if silent:\n",
        "            cmd.extend(['--summary-interval=0', '--quiet'])\n",
        "            print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
        "\n",
        "        # Run download\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "\n",
        "        if silent:\n",
        "            print(\"Done!\")\n",
        "        else:\n",
        "            print(f\"Downloaded {filename} to {dest_dir}\")\n",
        "        return filename\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        error = e.stderr.strip() or \"Unknown error\"\n",
        "        print(f\"\\nError downloading {filename}: {error}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_UltraSharp = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/4x-UltraSharp.pth\", \"/content/ComfyUI/models/upscale_models\")\n",
        "x_foolhardy_Remacri = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/4x_foolhardy_Remacri.pth\", \"/content/ComfyUI/models/upscale_models\")\n",
        "x_AnimeSharp = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/4x-AnimeSharp.pth\", \"/content/ComfyUI/models/upscale_models\")\n",
        "if download_face_upscalers:\n",
        "    x_FaceUpSharpDAT = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/4xFaceUpSharpDAT.pth\", \"/content/ComfyUI/models/upscale_models\")\n",
        "    x_FaceUpSharpLDAT = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/4xFaceUpSharpLDAT.safetensors\", \"/content/ComfyUI/models/upscale_models\")\n",
        "\n",
        "flux_model = model_download(\"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q8_0.gguf\", \"/content/ComfyUI/models/unet\")\n",
        "# flux_model = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/flux1-dev-fp8.safetensors\", \"/content/ComfyUI/models/unet\")\n",
        "flux_vae = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/ae.sft\", \"/content/ComfyUI/models/vae\")\n",
        "flux_clip_l = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/clip_l.safetensors\", \"/content/ComfyUI/models/clip\")\n",
        "flux_t5xxl = model_download(\"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/t5xxl_fp8_e4m3fn.safetensors\", \"/content/ComfyUI/models/clip\")\n",
        "\n",
        "clip_loader = DualCLIPLoader()\n",
        "unet_loader =  UnetLoaderGGUF()\n",
        "# unet_loader =  UNETLoader()\n",
        "vae_loader =   VAELoader()\n",
        "load_lora = LoraLoaderModelOnly()\n",
        "load_image = LoadImage()\n",
        "save_image = SaveImage()\n",
        "upscale_model_loader = UpscaleModelLoader()\n",
        "positive_prompt_encode = CLIPTextEncodeFlux()\n",
        "negative_prompt_encode = CLIPTextEncodeFlux()\n",
        "upscaler = UltimateSDUpscale()\n",
        "noUpscale = UltimateSDUpscaleNoUpscale()\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save single frame as PNG image.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
        "\n",
        "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(frame).save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "# def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "#     output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
        "\n",
        "#     frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "#     with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "#         for frame in frames:\n",
        "#             writer.append_data(frame)\n",
        "\n",
        "#     return output_path\n",
        "\n",
        "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
        "\n",
        "    frames = []\n",
        "    for i, img in enumerate(images):\n",
        "        try:\n",
        "\n",
        "            if isinstance(img, torch.Tensor):\n",
        "                img = img.cpu().numpy()\n",
        "\n",
        "            # print(f\"Frame {i} initial shape: {img.shape}, dtype: {img.dtype}, max: {img.max()}\")  # Debug\n",
        "\n",
        "\n",
        "            if img.max() <= 1.0:\n",
        "                img = (img * 255).astype(np.uint8)\n",
        "            else:\n",
        "                img = img.astype(np.uint8)\n",
        "\n",
        "\n",
        "            if len(img.shape) == 4:  # Batch dimension? (N, C, H, W)\n",
        "                img = img[0]  # Take first image in batch\n",
        "\n",
        "            if len(img.shape) == 3:\n",
        "                if img.shape[0] in (1, 3, 4):  # CHW format\n",
        "                    img = np.transpose(img, (1, 2, 0))\n",
        "                elif img.shape[2] > 4:  # Too many channels\n",
        "                    img = img[:, :, :3]\n",
        "            elif len(img.shape) == 2:\n",
        "                img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "            # print(f\"Frame {i} processed shape: {img.shape}\")  # Debug\n",
        "\n",
        "            # Final validation\n",
        "            if len(img.shape) != 3 or img.shape[2] not in (1, 3, 4):\n",
        "                raise ValueError(f\"Invalid frame shape after processing: {img.shape}\")\n",
        "\n",
        "            frames.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame {i}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    try:\n",
        "        with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "            for i, frame in enumerate(frames):\n",
        "                # print(f\"Writing frame {i} with shape: {frame.shape}\")  # Debug\n",
        "                writer.append_data(frame)\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing video: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    return output_path\n",
        "\n",
        "import cv2\n",
        "import shutil\n",
        "from IPython.display import Video\n",
        "import datetime\n",
        "\n",
        "\n",
        "def upload_file():\n",
        "    \"\"\"Handle file upload (image or video) and return paths.\"\"\"\n",
        "    os.makedirs('/content/ComfyUI/input', exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    paths = []\n",
        "    for filename in uploaded.keys():\n",
        "        src_path = f'/content/ComfyUI/{filename}'\n",
        "        dest_path = f'/content/ComfyUI/input/{filename}'\n",
        "        shutil.move(src_path, dest_path)\n",
        "        paths.append(dest_path)\n",
        "        print(f\"File saved to: {dest_path}\")\n",
        "\n",
        "    return paths[0] if paths else None\n",
        "\n",
        "def extract_frames(video_path, max_frames=None):\n",
        "    \"\"\"Extract frames from video and return as a list of images.\"\"\"\n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "    frames = []\n",
        "\n",
        "    while True:\n",
        "        success, frame = vidcap.read()\n",
        "        if not success or (max_frames and len(frames) >= max_frames):\n",
        "            break\n",
        "\n",
        "        # Convert from BGR to RGB (keeping as numpy array)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(frame)\n",
        "\n",
        "    if not frames:\n",
        "        return None, fps\n",
        "\n",
        "    print(f\"Extracted {len(frames)} frames\")\n",
        "    return frames, fps\n",
        "\n",
        "\n",
        "\n",
        "def select_every_n_frame(\n",
        "    frames,\n",
        "    fps,\n",
        "    n,\n",
        "    skip_first=0,\n",
        "    max_output_frames=0\n",
        "):\n",
        "\n",
        "    if not frames or n < 1:\n",
        "        raise ValueError(\"Frames must be a non-empty list and n must be >= 1\")\n",
        "\n",
        "    frames_to_use = frames[skip_first:]\n",
        "\n",
        "    if not frames_to_use:\n",
        "        print(\"No frames available after skipping.\")\n",
        "        return [], 0.0\n",
        "\n",
        "    # Select every nth frame\n",
        "    selected_frames = frames_to_use[::n]\n",
        "\n",
        "    # Cap output if needed\n",
        "    if max_output_frames != 0 and len(selected_frames) > max_output_frames:\n",
        "        selected_frames = selected_frames[:max_output_frames]\n",
        "\n",
        "    # Adjust fps\n",
        "    adjusted_fps = fps / n\n",
        "\n",
        "    # print(f\"Original total frames: {len(frames)}\")\n",
        "    # print(f\"Skipped first {skip_first} frames\")\n",
        "    # print(f\"Selected every {n}th frame -> {len(selected_frames)} frames\")\n",
        "    if max_output_frames:\n",
        "        print(f\"Frame cap: {max_output_frames} -> Final output: {len(selected_frames)} frames\")\n",
        "    print(f\"Adjusted FPS: {adjusted_fps:.2f} -> Final output: {len(selected_frames)} frame\")\n",
        "\n",
        "    return selected_frames, adjusted_fps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_video(video_path):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    video_data = open(video_path,'rb').read()\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    if video_path.lower().endswith('.mp4'):\n",
        "        mime_type = \"video/mp4\"\n",
        "    elif video_path.lower().endswith('.webm'):\n",
        "        mime_type = \"video/webm\"\n",
        "    elif video_path.lower().endswith('.webp'):\n",
        "        mime_type = \"image/webp\"\n",
        "    else:\n",
        "        mime_type = \"video/mp4\"  # default\n",
        "\n",
        "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=512 controls autoplay loop>\n",
        "        <source src=\"{data_url}\" type=\"{mime_type}\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "def upscale_input(\n",
        "    image_path: str = None,\n",
        "    positive_prompt: str = \"\",\n",
        "    positive_prompt2: str = \"\",\n",
        "    negative_prompt: str = \"\",\n",
        "    negative_prompt2: str = \"\",\n",
        "    guidance: float = 3.5,\n",
        "    upscale_by: float = 2,\n",
        "    seed: int = 0,\n",
        "    steps: int = 20,\n",
        "    cfg: float = 1.0,\n",
        "    sampler_name: str = \"dpmpp_2m\",\n",
        "    scheduler: str = \"karras\",\n",
        "    denoise: float = 0.2,\n",
        "    upscale_model: str = \"4x-UltraSharp.pth\",\n",
        "    mode_type: str = \"Linear\",\n",
        "    tile_width: int = 512,\n",
        "    tile_height: int = 512,\n",
        "    mask_blur: int = 16,\n",
        "    tile_padding: int = 32,\n",
        "    seam_fix_mode: str = \"Half Tile\",\n",
        "    seam_fix_denoise: float = 1.0,\n",
        "    seam_fix_width: int = 64,\n",
        "    seam_fix_mask_blur: int = 8,\n",
        "    seam_fix_padding: int = 32,\n",
        "    force_uniform_tiles: bool = True,\n",
        "    tiled_decode: bool = False,\n",
        "    select_every_nth: int = 1,\n",
        "    skip_first_frames: int = 0,\n",
        "    max_output_frames: str = None,\n",
        "    overwrite: bool = False,\n",
        "    use_lora: bool = False,\n",
        "    LoRA_Strength: float = 1.0\n",
        "\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(flux_t5xxl, flux_clip_l, \"flux\")[0]\n",
        "\n",
        "        frames=1\n",
        "\n",
        "        positive = positive_prompt_encode.encode(clip, positive_prompt, positive_prompt2, guidance)[0]\n",
        "        negative = negative_prompt_encode.encode(clip, negative_prompt, negative_prompt2, guidance)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Loading Unet Model...\")\n",
        "        model = unet_loader.load_unet(flux_model)[0]\n",
        "        # model = unet_loader.load_unet(flux_model, \"default\")[0]\n",
        "\n",
        "        if image_path is None:\n",
        "            print(\"Please upload an image or video file:\")\n",
        "            image_path = upload_file()\n",
        "        if image_path is None:\n",
        "            print(\"No image uploaded!\")\n",
        "        # loaded_image = load_image.load_image(image_path)[0]\n",
        "\n",
        "\n",
        "        print(\"Loading upscale model\")\n",
        "\n",
        "        if download_face_upscalers == False:\n",
        "            if upscale_model == \"4xFaceUpSharpDAT.pth\" or upscale_model == \"4xFaceUpSharpLDAT.safetensors\":\n",
        "                print(\"You did not download the selected upscale model. Using the default upscale model.\")\n",
        "                upscale_model = \"4x-UltraSharp.pth\"\n",
        "\n",
        "        upscale_model_load = upscale_model_loader.load_model(upscale_model)[0]\n",
        "\n",
        "        print(\"Loading VAE...\")\n",
        "        vae = vae_loader.load_vae(flux_vae)[0]\n",
        "\n",
        "        if use_lora:\n",
        "            if lora is not None:\n",
        "                print(\"Loading Lora...\")\n",
        "                model = load_lora.load_lora_model_only(model, lora, LoRA_Strength)[0]\n",
        "\n",
        "        output_path = \"\"\n",
        "        base_name = \"Upscaled\"\n",
        "        if not overwrite:\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            base_name += f\"_{timestamp}\"\n",
        "\n",
        "        try:\n",
        "            if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                # Single image processing\n",
        "                loaded_image = load_image.load_image(image_path)[0]\n",
        "                print(\"Upscaling image...\")\n",
        "                image_out = upscaler.upscale(\n",
        "                    image=loaded_image,\n",
        "                    model=model,\n",
        "                    positive=positive,\n",
        "                    negative=negative,\n",
        "                    vae=vae,\n",
        "                    upscale_by=upscale_by,\n",
        "                    seed=seed,\n",
        "                    steps=steps,\n",
        "                    cfg=cfg,\n",
        "                    sampler_name=sampler_name,\n",
        "                    scheduler=scheduler,\n",
        "                    denoise=denoise,\n",
        "                    upscale_model=upscale_model_load,\n",
        "                    mode_type=mode_type,\n",
        "                    tile_width=tile_width,\n",
        "                    tile_height=tile_height,\n",
        "                    mask_blur=mask_blur,\n",
        "                    tile_padding=tile_padding,\n",
        "                    seam_fix_mode=seam_fix_mode,\n",
        "                    seam_fix_denoise=seam_fix_denoise,\n",
        "                    seam_fix_mask_blur=seam_fix_mask_blur,\n",
        "                    seam_fix_width=seam_fix_width,\n",
        "                    seam_fix_padding=seam_fix_padding,\n",
        "                    force_uniform_tiles=force_uniform_tiles,\n",
        "                    tiled_decode=tiled_decode,\n",
        "                )[0]\n",
        "\n",
        "\n",
        "\n",
        "                # output_path = \"\"\n",
        "                # base_name = \"ComfyUI\"\n",
        "                # if not overwrite:\n",
        "                #     timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                #     base_name += f\"_{timestamp}\"\n",
        "                print(\"Saving as PNG image...\")\n",
        "                output_path = save_as_image(image_out[0], base_name)\n",
        "                display(IPImage(filename=output_path))\n",
        "\n",
        "                del model\n",
        "                del vae\n",
        "                del upscale_model_load\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "            else:\n",
        "                # Video processing\n",
        "                frames, fps = extract_frames(file_uploaded)\n",
        "                frames, fps = select_every_n_frame(frames,fps,select_every_nth,skip_first_frames,max_output_frames)\n",
        "                upscaled_frames = []\n",
        "                # for i, frame in frames:\n",
        "                for i, frame in enumerate(frames):\n",
        "                    temp_path = \"/tmp/temp_frame.png\"\n",
        "                    cv2.imwrite(temp_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "                    loaded_image = load_image.load_image(temp_path)[0]\n",
        "\n",
        "                    print(f\"Upscaling frame {i+1} of {len(frames)} frames...\")\n",
        "\n",
        "                    upscaled_frame = upscaler.upscale(\n",
        "                        image=loaded_image,\n",
        "                        model=model,\n",
        "                        positive=positive,\n",
        "                        negative=negative,\n",
        "                        vae=vae,\n",
        "                        upscale_by=upscale_by,\n",
        "                        seed=seed,\n",
        "                        steps=steps,\n",
        "                        cfg=cfg,\n",
        "                        sampler_name=sampler_name,\n",
        "                        scheduler=scheduler,\n",
        "                        denoise=denoise,\n",
        "                        upscale_model=upscale_model_load,\n",
        "                        mode_type=mode_type,\n",
        "                        tile_width=tile_width,\n",
        "                        tile_height=tile_height,\n",
        "                        mask_blur=mask_blur,\n",
        "                        tile_padding=tile_padding,\n",
        "                        seam_fix_mode=seam_fix_mode,\n",
        "                        seam_fix_denoise=seam_fix_denoise,\n",
        "                        seam_fix_mask_blur=seam_fix_mask_blur,\n",
        "                        seam_fix_width=seam_fix_width,\n",
        "                        seam_fix_padding=seam_fix_padding,\n",
        "                        force_uniform_tiles=force_uniform_tiles,\n",
        "                        tiled_decode=tiled_decode\n",
        "                    )[0]\n",
        "                    upscaled_frames.append(upscaled_frame)\n",
        "\n",
        "\n",
        "\n",
        "                print(f\"Saving as MP4 with {len(upscaled_frames)} frames...\")\n",
        "                output_path = save_as_mp4(upscaled_frames, base_name, fps)\n",
        "                display_video(output_path)\n",
        "\n",
        "                del model\n",
        "                del vae\n",
        "                del upscale_model_load\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during upscaling/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e3zDkcE4GITb"
      },
      "outputs": [],
      "source": [
        "# @title Upload Image/Video\n",
        "\n",
        "file_uploaded = upload_file()\n",
        "display_upload = False # @param {type:\"boolean\"}\n",
        "if display_upload:\n",
        "    if file_uploaded.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        display(IPImage(filename=file_uploaded))\n",
        "    else:\n",
        "        display_video(file_uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7HnFqZEfGW0z"
      },
      "outputs": [],
      "source": [
        "# @title Upscale Image/Video\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Prompt Settings\n",
        "positive_prompt=\"\" # @param {\"type\":\"string\"}\n",
        "positive_prompt2=\"\" # @param {\"type\":\"string\"}\n",
        "negative_prompt=\"\" # @param {\"type\":\"string\"}\n",
        "negative_prompt2=\"\" # @param {\"type\":\"string\"}\n",
        "guidance=3.5 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":100.0,\"step\":0.1}\n",
        "# @markdown ---\n",
        "# @markdown ### Upscale Settings\n",
        "upscale_by=2 # @param {\"type\":\"slider\",\"min\":0.05,\"max\":4.0,\"step\":0.05}\n",
        "seed=0 # @param {\"type\":\"integer\"}\n",
        "steps = 20 # @param {\"type\":\"slider\",\"min\":0,\"max\":1000,\"step\":1}\n",
        "cfg = 7 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":1}\n",
        "sampler_name=\"euler\" # @param [\"uni_pc\", \"uni_pc_bh2\", \"ddim\",\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\",\"dpm_2\", \"dpm_2_ancestral\",\"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\",\"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\",\"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\",\"gradient_estimation\", \"er_sde\", \"seeds_2\", \"seeds_3\"]\n",
        "scheduler=\"normal\" # @param [\"simple\",\"normal\",\"karras\",\"exponential\",\"sgm_uniform\",\"ddim_uniform\",\"beta\",\"linear_quadratic\",\"kl_optimal\"]\n",
        "denoise=0.2 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":1.0,\"step\":0.01}\n",
        "upscale_model=\"4x-UltraSharp.pth\" # @param [\"4x-UltraSharp.pth\", \"4x_foolhardy_Remacri.pth\", \"4x-AnimeSharp.pth\", \"4xFaceUpSharpDAT.pth\", \"4xFaceUpSharpLDAT.safetensors\"]\n",
        "mode_type=\"Linear\" # @param [\"Linear\", \"Chess\", \"None\"]\n",
        "tile_width = 512 # @param {\"type\":\"slider\",\"min\":64,\"max\":8192,\"step\":8}\n",
        "tile_height = 512 # @param {\"type\":\"slider\",\"min\":64,\"max\":8192,\"step\":8}\n",
        "mask_blur = 8 # @param {\"type\":\"slider\",\"min\":0,\"max\":64,\"step\":1}\n",
        "tile_padding = 32 # @param {\"type\":\"slider\",\"min\":0,\"max\":8192,\"step\":8}\n",
        "seam_fix_mode=\"None\" # @param [\"None\", \"Half Tile\", \"Half Tile + Intersections\", \"Band Pass\"]\n",
        "seam_fix_denoise=1.0 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":1.0,\"step\":0.01}\n",
        "seam_fix_width=64 # @param {\"type\":\"slider\",\"min\":0,\"max\":8192,\"step\":8}\n",
        "seam_fix_mask_blur=8 # @param {\"type\":\"slider\",\"min\":0,\"max\":64,\"step\":1}\n",
        "seam_fix_padding=16 # @param {\"type\":\"slider\",\"min\":0,\"max\":8192,\"step\":8}\n",
        "force_uniform_tiles=True # @param {type:\"boolean\"}\n",
        "tiled_decode=False # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "# @markdown ### LoRA Settings\n",
        "use_loRA=False # @param {type:\"boolean\"}\n",
        "LoRA_Strength=1.0 # @param {\"type\":\"slider\",\"min\":-100,\"max\":100,\"step\":0.01}\n",
        "# @markdown ---\n",
        "# @markdown ### Video Settings\n",
        "select_every_nth_frame = 1 # @param {\"type\":\"integer\"}\n",
        "skip_first_frames = 0 # @param {\"type\":\"integer\"}\n",
        "max_output_frames = 0 # @param {\"type\":\"integer\"}\n",
        "overwrite_previous_output=False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "upscale_input(\n",
        "    image_path=file_uploaded,\n",
        "    positive_prompt=positive_prompt,\n",
        "    positive_prompt2=positive_prompt2,\n",
        "    negative_prompt=negative_prompt,\n",
        "    negative_prompt2=negative_prompt2,\n",
        "    guidance=guidance,\n",
        "    upscale_by=upscale_by,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg=cfg,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    denoise=denoise,\n",
        "    upscale_model=upscale_model,\n",
        "    mode_type=mode_type,\n",
        "    tile_width=tile_width,\n",
        "    tile_height=tile_height,\n",
        "    mask_blur=mask_blur,\n",
        "    tile_padding=tile_padding,\n",
        "    seam_fix_mode=seam_fix_mode,\n",
        "    seam_fix_denoise=seam_fix_denoise,\n",
        "    seam_fix_width=seam_fix_width,\n",
        "    seam_fix_mask_blur=seam_fix_mask_blur,\n",
        "    seam_fix_padding=seam_fix_padding,\n",
        "    force_uniform_tiles=force_uniform_tiles,\n",
        "    tiled_decode=tiled_decode,\n",
        "    select_every_nth = select_every_nth_frame,\n",
        "    skip_first_frames = skip_first_frames,\n",
        "    max_output_frames = max_output_frames,\n",
        "    overwrite=overwrite_previous_output,\n",
        "    use_lora=use_loRA,\n",
        "    LoRA_Strength=LoRA_Strength\n",
        "\n",
        ")\n",
        "\n",
        "clear_memory()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}